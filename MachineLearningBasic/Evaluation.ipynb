{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "aad7fa43305c5ed1fb127d263f3083b3588cd5af60f171b45496a79879bf8414"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Evaluation\n",
    "## 1. 성능 평가 지표 (Evaluation Metric)\n",
    "- 분류\n",
    "    - 회귀인 경우\n",
    "        - 실제값과 예측값의 오차 평균값에 기반\n",
    "    - 분류인 경우 \n",
    "        - 정확도 (Accuracy)\n",
    "        - 오차행렬 (Confusion Matrix)\n",
    "        - 정밀도 (Precision)\n",
    "        - 재현율 (Recall)\n",
    "        - F1 스코어\n",
    "        - ROC AUC"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### (1) 정확도 (Accuracy)\n",
    "```\n",
    "정확도 = 예측 결과가 동일한 데이터 건수 / 전체 예측 데이터 건수\n",
    "```\n",
    "- 실제 데이터에서 예측 데이터가 얼마나 같은지 판단\n",
    "- 불균형한 label data set에서는 성능 수치로 사용되면 X\n",
    "    - 데이터 분포도가 균일하지 않은 경우 정확도가 높은 수치가 나타날 수 있음 \n",
    "- 한계점 극복을 다른 지표들과 함께 적용해야함"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### (2) 오차 행렬 (Confusion Matrix)\n",
    "- 학습된 분류모델이 예측을 수행하면서 얼마나 confused되는지 보여주는 지표\n",
    "- 이진분류의 예측오류가 얼마인지\n",
    "- 어떤 유형의 예측 오류가 발생하고 있는지 나타내는 지표\n",
    "- Confusion_matrix() API제공\n",
    "- 불균형한 dataset에서는 positive데이터 건수가 매우 작아서 Negative로 예측 정확도가 높아지는 경향 있음\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### (3) 정밀도 (Precision) 와 재현률 (Recall) \n",
    "- 불균형한 dataset에서 더 선호되는 평가 지표\n",
    "- Positive dataset의 예측 성능에 좀 더 초점 맞춘 평가 지표\n",
    "- 이진분류 모델의 업무 특성에 따라 특정 평가 지표가 더 중요하게 간주\n",
    "    - 재현률이 정밀도보다 상대적으로 중요한 업무가 더 많음 \n",
    "- 가장 좋은 성능 평가는 재현율 & 정밀도 모두 높은 수치 가지는 것\n",
    "<br>\n",
    "\n",
    "</br>\n",
    "\n",
    "#### 정밀도\n",
    "```\n",
    "정밀도 = TP / (FP + TP)\n",
    "```\n",
    "- 예측을 Positive로 한 대상 중에 예측과 실제값이 Positive로 일치한 데이터의 비율 의미\n",
    "- Positive 예측 성능을 더 정밀하게 측정\n",
    "- prcision_score() 사용\n",
    "- Ex1 ) 스펨메일 여부 판단 모델\n",
    "    - 실제 Positive인 것을 Negative로 판단하면 사용자가 불편함 느끼는 정도임\n",
    "    - 반면 실제 Negative인 것을 Positive로 판단하면 메일을 아예 받지 못해서 업무에 차질 생김\n",
    "\n",
    "#### 재현률 \n",
    "```\n",
    "재현률 = TP / (FN + TP)\n",
    "```\n",
    "- 실제값이 Positive인 대상 중 예측과 실제값이 Positive로 일치한 데이터의 비율 의미 \n",
    "- 민감도 (Sensitivity) & TPR ( True Positive Rate)라고 불림 \n",
    "- recall_score() 사용\n",
    "- Ex1 ) 암판단 모델은 재현률이 더 중요!\n",
    "    - 실제 Positive인 환자를 Negative로 판단하면 큰일남\n",
    "    - 반면 Negative인 환자를 Positive로 판단하면 별 문제 없음\n",
    "- Ex2 ) 금융 사기 적발 모델\n",
    "    - 실제 Positive인 건을 Negative로 판단하면 손해가 커짐\n",
    "    - 반면 Negative인 건을 Positive로 판단하면 재검증 절차만을 가짐"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clf_eval(y_test, pred):\n",
    "    # 오차행렬\n",
    "    confusion=confusion_matrix(y_test,pred)\n",
    "    # 정확도\n",
    "    accuracy=accuracy_score(y_test, pred)\n",
    "    # 정밀도\n",
    "    precision=precision_score(y_test, pred)\n",
    "    # 재현률\n",
    "    recall=recall_score(y_test,pred)\n",
    "    print(confusion)\n",
    "    print(accuracy,precision,recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본 데이터 재로딩, 데이터 가공, 학습 데이터 / 테스트 데이터 분할\n",
    "titanic=pd.read_csv('C:/Users/admin/dataset/titanic_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# null처리\n",
    "def fillnan(df):\n",
    "    df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "    df['Cabin'].fillna('N',inplace=True)\n",
    "    df['Embarked'].fillna('N', inplace=True)\n",
    "    df['Fare'].fillna(0, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불필요한 속성 제거\n",
    "def drop_features(df):\n",
    "    df.drop(['PassengerId','Name', 'Ticket'], axis=1,inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding 수행\n",
    "def format_features(df):\n",
    "    df['Cabin']=df['Cabin'].str[:1]\n",
    "    features=['Cabin', 'Sex','Embarked']\n",
    "    for f in features:\n",
    "        le=preprocessing.LabelEncoder()\n",
    "        le=le.fit(df[f])\n",
    "        df[f]=le.transform(df[f])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앞에서 설정한 데이터 전처리 함수 호출( 전체 )\n",
    "def transform_features(df):\n",
    "    df=fillnan(df)\n",
    "    df=drop_features(df)\n",
    "    df=format_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df=titanic['Survived']\n",
    "x_df=titanic.drop('Survived', axis=1)\n",
    "x_df=transform_features(x_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test, y_train,y_test=train_test_split(x_df,y_df, test_size=0.20, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrclf=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[108  10]\n",
      " [ 14  47]]\n",
      "0.8659217877094972 0.8245614035087719 0.7704918032786885\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lrclf.fit(X_train, y_train)\n",
    "pred=lrclf.predict(X_test)\n",
    "get_clf_eval(y_test,pred)"
   ]
  },
  {
   "source": [
    "### Result\n",
    "```\n",
    "오차행렬 => [[108  10]\n",
    "             [ 14  47]]\n",
    "정확도 => 0.8659217877094972 \n",
    "정밀도 => 0.8245614035087719 \n",
    "재현율 => 0.7704918032786885\n",
    "```\n",
    "정밀도에 비해 낮은 재현율 가짐"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### 정밀도 / 재현율 트레이드 오프 (Trade-off)\n",
    "- 업무 특성상 정밀도 & 재현률이 강조되어야 하는 경우에 분류의 결정 임계값(Threshold) 조정해야함\n",
    "- 정밀도 & 재현율은 상호보완적이기 때문에 하나를 높이면 다른 하나는 떨어짐\n",
    "- 이를 정밀도 /재현율의 트레이드오프(Trade-off)라 함\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### predict_proba()\n",
    "- 개별 데이터별로 예측 확률을 반환 \n",
    "- 학습이 완료된 Classifier 객체에서 호출 가능\n",
    "- test feature 데이터 세트를 파라미터로 입력해주면 test feature 레코드의 개별 클래스 예측 확률을 반환"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}