{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "40aad76b6a08bf7c66d35880b5b9359a81633cf2405343e85202dcb9ce476e47"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Ensemble \n",
    "- 여러개의 분류기(Classifier)를 생성하고 예측을 결합하므로써 정확한 최종 예측 도출\n",
    "\n",
    "## ✔ Ensemble 학습의 유형\n",
    "- Voting\n",
    "    - 여러개의 분류기(Classifier)가 투표를 통해 최종 예측 결과 결정\n",
    "    - 서로 다른 알고리즘을 가진 분류기(Classifier)를 결합하므로써\n",
    "- Bagging\n",
    "    - 여러개의 분류기(Classifier)가 투표를 통해 최종 예측 결과 결정\n",
    "    - 각각의 분류기(Classifier)가 같은 유형의 알고리즘이지만 data sampling을 서로 다르게 학습해 voting수행\n",
    "    - Random Forest\n",
    "- Boosting\n",
    "    - 여러개의 분류기가 순차적으로 학습 수행 \n",
    "    - 앞에서 학습한 분류기가 예측이 틀린 데이터에 대해 올바르게 예측할 수 있도록 다음 분류기에서 가중치를 부여하면서 학습과 예측 진행\n",
    "    - Gradient Boost, XGBoost, LightGBM\n",
    "- Stacking\n",
    "    - 여러개의 다른 모델의 예측 결과값을 다시 학습 데이터로 만들어서 다른 모델로 재학습시켜 결과 예측\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 1. Voting\n",
    "### (1) Hard Voting\n",
    "- 예측한 결괏값들 중 다수의 분류기가 결정한 예측값을 최종 Voting 결과값으로 선정\n",
    "\n",
    "### (2) Soft Voting\n",
    "- 분류기들의 label값 결정 확률을 모두 더하고 평균내서 확률이 가장 높은 label값을 최종 Voting 결과값으로 선정\n",
    "- 일반적으로 사용"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## ✔ Voting 분류기 ( Voting Classifier )\n",
    "- Voting방식의 Ensemble 이용해 위스콘신 유방암 Dataset 예측\n",
    "- Logistic Regression & KNN 기반으로 Voting Classifier 생성"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer=load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(cancer.data,columns=cancer.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean radius</th>\n      <th>mean texture</th>\n      <th>mean perimeter</th>\n      <th>mean area</th>\n      <th>mean smoothness</th>\n      <th>mean compactness</th>\n      <th>mean concavity</th>\n      <th>mean concave points</th>\n      <th>mean symmetry</th>\n      <th>mean fractal dimension</th>\n      <th>...</th>\n      <th>worst radius</th>\n      <th>worst texture</th>\n      <th>worst perimeter</th>\n      <th>worst area</th>\n      <th>worst smoothness</th>\n      <th>worst compactness</th>\n      <th>worst concavity</th>\n      <th>worst concave points</th>\n      <th>worst symmetry</th>\n      <th>worst fractal dimension</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>17.99</td>\n      <td>10.38</td>\n      <td>122.80</td>\n      <td>1001.0</td>\n      <td>0.11840</td>\n      <td>0.27760</td>\n      <td>0.3001</td>\n      <td>0.14710</td>\n      <td>0.2419</td>\n      <td>0.07871</td>\n      <td>...</td>\n      <td>25.38</td>\n      <td>17.33</td>\n      <td>184.60</td>\n      <td>2019.0</td>\n      <td>0.1622</td>\n      <td>0.6656</td>\n      <td>0.7119</td>\n      <td>0.2654</td>\n      <td>0.4601</td>\n      <td>0.11890</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.0869</td>\n      <td>0.07017</td>\n      <td>0.1812</td>\n      <td>0.05667</td>\n      <td>...</td>\n      <td>24.99</td>\n      <td>23.41</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n      <td>0.1238</td>\n      <td>0.1866</td>\n      <td>0.2416</td>\n      <td>0.1860</td>\n      <td>0.2750</td>\n      <td>0.08902</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.1974</td>\n      <td>0.12790</td>\n      <td>0.2069</td>\n      <td>0.05999</td>\n      <td>...</td>\n      <td>23.57</td>\n      <td>25.53</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n      <td>0.1444</td>\n      <td>0.4245</td>\n      <td>0.4504</td>\n      <td>0.2430</td>\n      <td>0.3613</td>\n      <td>0.08758</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11.42</td>\n      <td>20.38</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>0.14250</td>\n      <td>0.28390</td>\n      <td>0.2414</td>\n      <td>0.10520</td>\n      <td>0.2597</td>\n      <td>0.09744</td>\n      <td>...</td>\n      <td>14.91</td>\n      <td>26.50</td>\n      <td>98.87</td>\n      <td>567.7</td>\n      <td>0.2098</td>\n      <td>0.8663</td>\n      <td>0.6869</td>\n      <td>0.2575</td>\n      <td>0.6638</td>\n      <td>0.17300</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20.29</td>\n      <td>14.34</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>0.10030</td>\n      <td>0.13280</td>\n      <td>0.1980</td>\n      <td>0.10430</td>\n      <td>0.1809</td>\n      <td>0.05883</td>\n      <td>...</td>\n      <td>22.54</td>\n      <td>16.67</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n      <td>0.1374</td>\n      <td>0.2050</td>\n      <td>0.4000</td>\n      <td>0.1625</td>\n      <td>0.2364</td>\n      <td>0.07678</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 30 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "source": [
    "### voting 분류기 만들기"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개별 model\n",
    "lr_clf=LogisticRegression()\n",
    "knn_clf=KNeighborsClassifier(n_neighbors=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개별 model을 soft Voting기반의 Ensemble Model로 구현\n",
    "vo_clf=VotingClassifier(estimators=[('LR',lr_clf),('KNN',knn_clf)], voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test, y_train, y_test=train_test_split(cancer.data, cancer.target, test_size=0.2, random_state=156)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\kimjh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Voting classifier 학습/ 예측 / 평가\n",
    "vo_clf.fit(X_train, y_train)\n",
    "pred=vo_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LogisticRegression 의 정확도 0.9385964912280702\n",
      "KNeighborsClassifier 의 정확도 0.9385964912280702\n",
      "C:\\Users\\kimjh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# 개별 model의 학습 / 예측 평가\n",
    "classifier=[lr_clf, knn_clf]\n",
    "for cl in classifier:\n",
    "    cl.fit(X_train, y_train)\n",
    "    pred=cl.predict(X_test)\n",
    "    class_name=cl.__class__.__name__\n",
    "    print(class_name, \"의 정확도\", accuracy_score(y_test, pred))"
   ]
  },
  {
   "source": [
    "### Result\n",
    "- Voting Classifier의 정확도가 더 높게 나타나긴 했지만 항상 그런것은 아님"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 2. Bagging\n",
    "- 같은 알고리즘으로 여러 개의 분류기를 만들어 Voting으로 최종 결정\n",
    "- Ensemble Algorithm 중 가장 빠른 수행속도 가짐 \n",
    "- 여러개의 Decision Tree 분류기가 전체 data에서 bagging 방식으로 각자의 data를 sampling 해 개별적으로 학습 수행\n",
    "\n",
    "## ✔ Bootstrapping \n",
    "- 여러개의 dataset을 중첩되게 분리 \n",
    "\n",
    "## ✔ Random Forest의 Hyper Parameter & Tuning\n",
    "- 트리 기반 Ensemble Algorithm의 단점 \n",
    "    - Hyper Parameter가 너무 많아서 Tuning을 위한 시간이 많이 소요\n",
    "    - 시간을 많이 소요했음에도 Tuning 후 예측 성능이 크게 향상 X\n",
    "- n_estimators \n",
    "    - Random Forest에서 Decision Tree의 갯수 지정\n",
    "    - default => 10 개\n",
    "    - 갯수를 늘릴수록 학습 수행 시간이 오래 걸림\n",
    "- max_features\n",
    "    - Random Forest의 Tree를 분할하는 feature를 참조할 때 sqrt(전체 feature 갯수)만큼 참조"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 3. Boosting\n",
    "- 여러개의 약한 학습기를 순차적으로 학습 & 예측하면서 잘못한 데이터에 가중치를 부여해 오류를 개선하면서 학습\n",
    "\n",
    "## ✔ AdaBoost\n",
    "    - 오류 data에 가중치 부여하면서 Boosting 수행\n",
    "\n",
    "## ✔ GBM (Gradient Boosting Machine)\n",
    "    - AdaBoost와 유사하나 경사 하강법을 이용해 가중치 update\n",
    "    - 과적합에도 강한 뛰어난 예측 성능 가짐\n",
    "    - 수행시간 오래걸린다는 단점 \n",
    "\n",
    "### 경사 하강법 (Gradient Descent)\n",
    "- 오차를 최소화하는 방향성을 가지고 반복적으로 가중치 값을 update\n",
    "- 회귀 문제, 분류문제 둘 다 해결 가능\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## ✔ XGBoost (eXtra Gradient Boost)\n",
    "- 분류에 있어서 다른 ML보다 뛰어남\n",
    "- GBM에 기반\n",
    "    - GBM의 단점인 느린 수행 시간 & 과적합 규제 부재(Regularization) 등의 문제를 해결 \n",
    "- 병렬 CPU 환경에서 병렬 학습 가능  \n",
    "- Tree Pruning \n",
    "    - 더 이상 긍정 이득이 없는 분할을 가지치기"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}