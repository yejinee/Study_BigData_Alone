{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "aad7fa43305c5ed1fb127d263f3083b3588cd5af60f171b45496a79879bf8414"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 교차 검증"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 과적합 (Overfitting)\n",
    "- model이 학습 data에만 과도하게 최적화\n",
    "- 실제 예측을 수행하는 경우 예측 성능이 떨어짐\n",
    "\n",
    "## 교차검증\n",
    "- 과적합 문제를 해결하기 위함\n",
    "- 데이터의 편중을 막기 위해 여러set로 구성된 train dataset과 검증 dataset에서 학습과 평가 수행\n",
    "- 각 세트에서 수행한 평가 결과에 따라 하이퍼 파라미터 튜닝등의 모델 최적화 가능"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 1) K 폴드 교차 검증\n",
    "- k개의 데이터 폴드 세트를 만들어서 각 폴드 세트에 학습과 검증 평가를 반복적 수행\n",
    "\n",
    "#### 순서\n",
    "1. dataset을 K등분 함\n",
    "2. 첫번째 반복에서 (k-1)개를 학습 dataset, 1개를 검증 dataset으로 설정\n",
    "3. 학습 dataset에서 학습 수행 검증 dataset에서 평가 수행\n",
    "4. 검증 dataset을 바꿔가면서 총 k번 반복 수행\n",
    "5. K개의 예측 평가 구하면 평균해서 K 폴드 평가 결과로 반여"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris=load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=iris.data\n",
    "label=iris.target\n",
    "clf=DecisionTreeClassifier(random_state=156)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold=KFold(n_splits=5) # 5개의 폴드 세트로 분리하는 KFold 객체\n",
    "acc=[] # 폴드 세트 별 정확도를 담을 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# iris에는 총 150개의 data들이 있음\n",
    "features.shape[0]"
   ]
  },
  {
   "source": [
    "### KFold 객체에 split() 호출해 전체 data를 5개로 분리\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3 1.0 120 30\n4 0.9667 120 30\n5 0.8667 120 30\n6 0.9333 120 30\n7 0.7333 120 30\n"
     ]
    }
   ],
   "source": [
    "# k Fold 객체의 split()호출하면 폴드 별 학습용, 검증용 테스트의 row index를 array로 반환\n",
    "for train_index, test_idx in kfold.split(features):\n",
    "    # k Fold.split() 로 반환 된 index 이용해 학습용, 검증용 test data 추출\n",
    "    X_train, X_test=features[train_index], features[test_idx]\n",
    "    y_train, y_test=label[train_index],label[test_idx]\n",
    "\n",
    "    # 학습 및 예측 \n",
    "    clf.fit(X_train, y_train)\n",
    "    pred=clf.predict(X_test)\n",
    "    n_iter+=1\n",
    "\n",
    "    # 반복 시마다 정확도 측정\n",
    "    accuracy=np.round(accuracy_score(y_test,pred),4)\n",
    "    train_size=X_train.shape[0]\n",
    "    test_size=X_test.shape[0]\n",
    "    print(n_iter, accuracy,train_size,test_size)\n",
    "    acc.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# 각 횟수 별 정확도 평균 내서 평균 정확도 계산 \n",
    "np.mean(acc)"
   ]
  },
  {
   "source": [
    "### Result\n",
    "- 5번의 교차 검증 결과 평균 검증 정확도는 0.9"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 2) Stratified K 폴드 교차 검증\n",
    "- 불균형한 분포도를 가진 레이블( 결정 class ) 데이터 집합을 위한 k 폴드 방식\n",
    "- label data 집합이 원본 데이터 집합의 label 분포를 train/test set에 제대로 분배하지 못하는 경우 문제 해결\n",
    "- 원본 data의 label분포를 먼저 고려한 뒤 분포와 동일하게 dataset 분배\n",
    "- 특정 레이블 값이 특이하게 많거나 매우 적어서 값의 분포가 한쪽으로 치우치는 경우 사용\n",
    "    - Ex) 대출 사기 데이터 예측하는 경우"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "irisdf=pd.DataFrame(data=iris,columns=iris.feature_names)\n",
    "irisdf['label']=iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf=StratifiedKFold(n_splits=3)\n",
    "n_iter=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "교차검증 4\n학습 레이블 데이터 분포\n 2    33\n1    33\n0    33\nName: label, dtype: int64\ntest 레이블 데이터 분포\n 2    17\n1    17\n0    17\nName: label, dtype: int64\n교차검증 5\n학습 레이블 데이터 분포\n 2    33\n1    33\n0    33\nName: label, dtype: int64\ntest 레이블 데이터 분포\n 2    17\n1    17\n0    17\nName: label, dtype: int64\n교차검증 6\n학습 레이블 데이터 분포\n 2    34\n1    34\n0    34\nName: label, dtype: int64\ntest 레이블 데이터 분포\n 2    16\n1    16\n0    16\nName: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_idx in skf.split(irisdf,irisdf['label']):\n",
    "    n_iter+=1\n",
    "    label_train=irisdf['label'].iloc[train_index]\n",
    "    label_test=irisdf['label'].iloc[test_idx]\n",
    "    print(\"교차검증\", n_iter)\n",
    "    print(\"학습 레이블 데이터 분포\\n\", label_train.value_counts())\n",
    "    print(\"test 레이블 데이터 분포\\n\", label_test.value_counts())"
   ]
  },
  {
   "source": [
    "### Result\n",
    "- 학습 label & 검증 label data값의 분포도가 동일하게 할당"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_clf=DecisionTreeClassifier(random_state=156)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "skfold=StratifiedKFold(n_splits=3)\n",
    "n_iter=0\n",
    "cv_accuracy=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_idx, test_idx in skfold.split(features,label):\n",
    "    X_train, X_test=features[train_idx],features[test_idx]\n",
    "    y_train, y_test= label[train_idx], label[test_idx]\n",
    "    # 학습 & 예측\n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred=dt_clf.predict(X_test)\n",
    "\n",
    "    # 반복 시마다 정확도 측정\n",
    "    n_iter+=1\n",
    "    accuracy=np.round(accuracy_score(y_test,pred),4)\n",
    "    train_size=X_train.shape[0]\n",
    "    test_size=X_test.shape[0]\n",
    "    cv_accuracy.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "교차 검증 별 정확도 [0.9804 0.9216 0.9792]\n 평균 검증 정확도  0.9604\n"
     ]
    }
   ],
   "source": [
    "print('교차 검증 별 정확도', np.round(cv_accuracy,4))\n",
    "print(' 평균 검증 정확도 ', np.mean(cv_accuracy))"
   ]
  },
  {
   "source": [
    "### Result\n",
    "- 평균 검증 정확도가 96.04% 로 측정\n",
    "- 왜곡된 label dataset에서는 반드시 Stratified K 폴드 이용해 교차 검증"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Cross_val_score()\n",
    "- 교차 검증 편리하게 수행 가능\n",
    "- Stratified K 폴드 방식으로 label값의 분포에 따라 Dataset 분할\n",
    "- 회귀의 경우에는 k 폴드 방식으로 수행\n",
    "- 내부에서 estimator를 학습(fit), 예측(predict), 평가(evaluation) 시켜줌\n",
    "\n",
    "<br> </br>\n",
    "\n",
    "- Options\n",
    "    - estimator : Classifier & Regressor\n",
    "    - X : feature Dataset\n",
    "    - Y : Label Dataset\n",
    "    - scoring : 예측 성능 평가 지표\n",
    "    - cv : 교차 검증 폴드 수 의미\n",
    "\n",
    "    "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score,cross_validate\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris=load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_clf=DecisionTreeClassifier(random_state=156)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=iris.data\n",
    "label=iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "교차 검증별 정확도 [0.9804 0.9216 0.9792]\n평균 검증 정확도 0.9604\n"
     ]
    }
   ],
   "source": [
    "# 성능 지표는 정확도 (accuracy), 교차 검증 set는 3개\n",
    "scores=cross_val_score(dt_clf,data,label,scoring='accuracy',cv=3)\n",
    "print(\"교차 검증별 정확도\", np.round(scores,4))\n",
    "print(\"평균 검증 정확도\", np.round(np.mean(scores),4))"
   ]
  },
  {
   "source": [
    "## GridSearchCV \n",
    "- 교차 검증과 최적 하이퍼 파라미터 튜닝을 한번에 해줌\n",
    "- Hyper Parameter를 순차적으로 입력하면서 최적의 Parameter 도출 방안을 제공\n",
    "- train data를 cv만큼 폴딩 셑트로 분할 & param_grid 에 있는 파라미터를 순차적 변경하면서 학습/평가 수행 \n",
    "- fit()수행 이후 최고 성능을 나타낸 hyper Parameter 값과 그때의 평가 결과가 best_paeams_ , best_score_ 속성에 저장\n",
    "- 최적 성능 나타내는 hyper Parameter로 Estimator학습해 best_estimator_로 저장\n",
    "   \n",
    "### Hyper Parameter\n",
    "- 이 값을 조정해 알고리즘의 예측 성능 개선 가능\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Ex) Decision Tree Algorithm의 hyper Parameter를 순차적으로 변경하면서 최고 성능 가지는 parameter조합 찾기\n",
    "- Decision Tree의 중요 hyper parameter : max_depth & min_sample_split\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_parameter={'max_depth':[1,2,3],\n",
    "            'min_samples_split':[2,3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris=load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(iris.data,iris.target, test_size=0.2, random_state=121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree=DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary 형태로 Parameter 설정\n",
    "parameter={'max_depth':[1,2,3],\n",
    "            'min_samples_split':[2,3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Param_grid의 하이퍼 파라미터를 3개의 train,test set fold로 나누어 테스트\n",
    "# refit =True가 default. ( 가장 좋은 parameter 설정으로 재학습 시킴)\n",
    "grid_dtree=GridSearchCV(dtree,param_grid=parameter,cv=3,refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort=False, random_state=None,\n",
       "                                              splitter='best'),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'max_depth': [1, 2, 3], 'min_samples_split': [2, 3]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "# Param_grid의 하이퍼 파라미터를 순차적으로 학습 / 평가\n",
    "grid_dtree.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                     params  mean_test_score  rank_test_score  \\\n",
       "0  {'max_depth': 1, 'min_samples_split': 2}         0.700000                5   \n",
       "1  {'max_depth': 1, 'min_samples_split': 3}         0.700000                5   \n",
       "2  {'max_depth': 2, 'min_samples_split': 2}         0.958333                3   \n",
       "3  {'max_depth': 2, 'min_samples_split': 3}         0.958333                3   \n",
       "4  {'max_depth': 3, 'min_samples_split': 2}         0.975000                1   \n",
       "5  {'max_depth': 3, 'min_samples_split': 3}         0.975000                1   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  \n",
       "0              0.700                0.7               0.70  \n",
       "1              0.700                0.7               0.70  \n",
       "2              0.925                1.0               0.95  \n",
       "3              0.925                1.0               0.95  \n",
       "4              0.975                1.0               0.95  \n",
       "5              0.975                1.0               0.95  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>params</th>\n      <th>mean_test_score</th>\n      <th>rank_test_score</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n      <td>0.700000</td>\n      <td>5</td>\n      <td>0.700</td>\n      <td>0.7</td>\n      <td>0.70</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n      <td>0.700000</td>\n      <td>5</td>\n      <td>0.700</td>\n      <td>0.7</td>\n      <td>0.70</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n      <td>0.958333</td>\n      <td>3</td>\n      <td>0.925</td>\n      <td>1.0</td>\n      <td>0.95</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n      <td>0.958333</td>\n      <td>3</td>\n      <td>0.925</td>\n      <td>1.0</td>\n      <td>0.95</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n      <td>0.975000</td>\n      <td>1</td>\n      <td>0.975</td>\n      <td>1.0</td>\n      <td>0.95</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n      <td>0.975000</td>\n      <td>1</td>\n      <td>0.975</td>\n      <td>1.0</td>\n      <td>0.95</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "scores_df=pd.DataFrame(grid_dtree.cv_results_)\n",
    "scores_df[['params','mean_test_score','rank_test_score','split0_test_score','split1_test_score','split2_test_score']]"
   ]
  },
  {
   "source": [
    "### Result\n",
    "- params : 수행시에 적용 된 hyper parameter 값\n",
    "- rank_test_score 가 1인 것이 예측 성능이 1위\n",
    "- mean_test_score : cv의 폴딩 테스트 셋에 대해 총 수행한 평가 평균값\n",
    "\n",
    "<br> </br>\n",
    "\n",
    "max_depth=3 & min_samples_split=2 일때 rank_test_score=1이므로 예측 성능이 1위  \n",
    "이때의 mean_test_score=0.975로 제일 높은 것을 알 수 있음"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "최적의 parameter {'max_depth': 3, 'min_samples_split': 2}\n최고 정확도 0.975\n"
     ]
    }
   ],
   "source": [
    "print(\"최적의 parameter\", grid_dtree.best_params_)\n",
    "print('최고 정확도', grid_dtree.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refit으로 이미 학습된 estimator반환\n",
    "estimator=grid_dtree.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "test dataset 정확도 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "pred=estimator.predict(x_test)\n",
    "print(\"test dataset 정확도\", accuracy_score(y_test,pred))"
   ]
  }
 ]
}